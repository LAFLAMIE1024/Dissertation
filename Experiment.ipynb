{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score, precision_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import xgboost as xgb\n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "concrete_compressive_strength = fetch_ucirepo(id=45)\n",
    "\n",
    "original_df = concrete_compressive_strength.data.original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test():\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.df = df\n",
    "\n",
    "        self.performance, self.test_performance = None, None\n",
    "\n",
    "        self.ratio_list = [1/15, 1/10, 1/5]\n",
    "        mechans = [\"MNAR\", \"MCAR\", \"MAR\"]\n",
    "        self.metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "        \n",
    "        self.mechan = \"Default\"\n",
    "\n",
    "        self.mar_dep_col, self.mar_tar_col, self.mnar_tar_col = \"ca\", \"thal\", \"cp\"\n",
    "        self.ratio_dict = {\"ratio_mcar\": 1/30, \"ratio_mar\": 1/30, \"ratio_mnar\": 1/30}\n",
    "        \n",
    "        self.mul_idx = pd.MultiIndex.from_product(\n",
    "            [mechans, [f\"{r:.3f}\" for r in self.ratio_list]],\n",
    "             names=[\"mechans\", \"ratios\"]\n",
    "        )\n",
    "\n",
    "        # Baseline Performance\n",
    "        print(\"Initializing... (Mechan: Default)\")\n",
    "        self.get_dict()\n",
    "        self.preproc()\n",
    "        self.baseperformance()\n",
    "        self.insert_null() # Create missing values first\n",
    "        self.impute() # Impute the generated missing data frame\n",
    "        self.cv_eval()\n",
    "        self.test_eval()\n",
    "        print(\"Done\")\n",
    "    \n",
    "    def preproc(self):\n",
    "        df = self.df.copy()\n",
    "        df.loc[df[(df['num'] > 0)].index.tolist(),'num'] = 1\n",
    "\n",
    "        dropped_df = df.dropna().astype(np.float64)\n",
    "        num_cols = dropped_df[self.num_li]\n",
    "        num_cols = (num_cols - num_cols.min()) / (num_cols.max() - num_cols.min())\n",
    "        dropped_df.loc[:, self.num_li] = num_cols\n",
    "\n",
    "        self.dropped_df = dropped_df\n",
    "\n",
    "        X = self.dropped_df.drop('num', axis=1)\n",
    "        y = self.dropped_df['num']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                            random_state=42)\n",
    "\n",
    "        self.X_train = X_train.reset_index(drop=True)\n",
    "        self.X_test = X_test.reset_index(drop=True)\n",
    "        self.y_train = y_train.reset_index(drop=True)\n",
    "        self.y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    def get_dict(self):\n",
    "        df = self.df.iloc[:,:-1]\n",
    "        self.names = df.columns.to_list()\n",
    "\n",
    "        self.names_dict = {}\n",
    "        for i, n in enumerate(df.columns.to_list()): self.names_dict[n] = i\n",
    "            \n",
    "        self.num_li = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca']\n",
    "        self.cat_li = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
    "\n",
    "        self.num_dict = {n:self.names_dict[n] for n in self.num_li}\n",
    "        self.cat_dict = {c:self.names_dict[c] for c in self.cat_li}\n",
    "\n",
    "    def baseperformance(self, md=4, fold=10):\n",
    "        self.clf = xgb.XGBClassifier(max_depth=md)\n",
    "        \n",
    "        scores = cross_validate(self.clf, self.X_train,\n",
    "                                 self.y_train, cv=fold, \n",
    "                                 scoring=self.metrics)\n",
    "        \n",
    "        score_frame = pd.DataFrame(scores, index=[f\"fold {n + 1}\" for n in range(fold)]).iloc[:,2:]\n",
    "        score_frame.columns = [f\"cv_{m}\" for m in self.metrics]\n",
    "        avg_performance = score_frame.mean()\n",
    "        avg_performance = pd.DataFrame(np.array(avg_performance).reshape(1,4), index=[\"Avg.\"], columns=avg_performance.index)\n",
    "\n",
    "        score_frame = pd.concat([score_frame, avg_performance])\n",
    "        score_frame = score_frame.map(lambda x: f\"{x * 100:.2f}%\")\n",
    "\n",
    "        s = score_frame.style\n",
    "        s = s.format_index(escape=\"latex\", axis=1)\n",
    "        res = s.to_latex( \n",
    "            position_float=\"centering\",\n",
    "            hrules=True,\n",
    "            ).replace(\n",
    "            '\\\\end{tabular}',\n",
    "            '\\\\end{tabular}\\n\\\\caption{Model training performance table (10 folds Cross validation)}\\n\\\\label{baseline_trainperf}')\n",
    "        print(\"\".join(res.split(\"'\")))\n",
    "\n",
    "        self.clf.fit(self.X_train, self.y_train)\n",
    "        y_pred = self.clf.predict(self.X_test)\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        accuracy  = accuracy_score(self.y_test, y_pred)\n",
    "        precision = precision_score(self.y_test, y_pred)\n",
    "        recall    = recall_score(self.y_test, y_pred)\n",
    "        f1        = f1_score(self.y_test, y_pred)\n",
    "\n",
    "        print(f\"Baseline performance on test set:\\n Accurarcy: {accuracy * 100: .2f}%, Precision: {precision * 100: .2f}%, Recall: {recall * 100: .2f}%, F1: {f1 * 100: .2f}%.\")\n",
    "\n",
    "\n",
    "    def insert_mcar(self, ratio, df): # Input the percentage of mcar, and the data frame\n",
    "        \n",
    "        # Input the length and width of the whole data frame\n",
    "        def generate_pair(length, width): \n",
    "            # generate a pair of numbers, which is the location of the missing entry\n",
    "            return (np.random.randint(0, length), np.random.randint(0, width)) \n",
    "        \n",
    "        # Number of null values to insert\n",
    "        num_nulls = int(ratio * (df.size))\n",
    "\n",
    "        # Randomly choose positions to insert null values\n",
    "        idx_pair = []\n",
    "\n",
    "        for _ in range(num_nulls):\n",
    "            \n",
    "            p = generate_pair(df.shape[0], df.shape[1])\n",
    "            while p in idx_pair: p = generate_pair(df.shape[0], df.shape[1])\n",
    "            idx_pair.append(p)\n",
    "            \n",
    "            df.iat[p[0], p[1]] = np.nan\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def insert_mar(self, ratio, df, dep_col, tar_col): \n",
    "        \n",
    "        \"\"\"\n",
    "        Input:\n",
    "            - The percentage of data MAR to be generated\n",
    "            - The data frame\n",
    "            - Dependent column name: str\n",
    "            - Index of the target column to be inserted\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the index of entries to be remvoed\n",
    "        target_idx = df[dep_col] < df[dep_col].quantile(ratio)\n",
    "\n",
    "        # Remove the entries in the target column\n",
    "        df.iloc[target_idx, self.names_dict[tar_col]] = np.nan\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def insert_mnar(self, ratio, df, tar_col): \n",
    "\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            - The percentage of data MNAR to be generated\n",
    "            - The data frame\n",
    "            - Target column name: str\n",
    "            - Index of the target column to be inserted\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get the index of entries to be remvoed\n",
    "        target_idx = df[tar_col] < df[tar_col].quantile(ratio)\n",
    "        \n",
    "        # Remove the entries in the target column\n",
    "        df.iloc[target_idx, self.names_dict[tar_col]] = np.nan\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def insert_null(self):\n",
    "        \"\"\"\n",
    "            Input:\n",
    "                - The data frame to be inserted\n",
    "                - Ratios for each missing mechanism\n",
    "        \"\"\"\n",
    "        # self.mechan = mechan if mechan is not None else None\n",
    "        missing_df = self.X_train.copy()\n",
    "\n",
    "        # Example\n",
    "        missing_df = self.insert_mar(self.ratio_dict[\"ratio_mcar\"], missing_df, self.mar_dep_col, self.mar_tar_col)\n",
    "        missing_df = self.insert_mnar(self.ratio_dict[\"ratio_mnar\"], missing_df, self.mnar_tar_col)\n",
    "        self.missing_df = self.insert_mcar(self.ratio_dict[\"ratio_mar\"], missing_df)\n",
    "\n",
    "    def cv(self, md=4, fold=10):\n",
    "    \n",
    "        param = {\n",
    "            \"max_depth\": md, \n",
    "            \"eta\": 1, \n",
    "            \"objective\": \"binary:logistic\"\n",
    "        }\n",
    "\n",
    "        dtrain = xgb.DMatrix(\n",
    "            data=self.X_train,\n",
    "            label=self.y_train\n",
    "        )\n",
    "        \n",
    "        res = xgb.cv(\n",
    "            param,\n",
    "            dtrain,\n",
    "            num_boost_round=10,\n",
    "            nfold=fold,\n",
    "            metrics=(\"error\"),\n",
    "            seed=42,\n",
    "            as_pandas = True\n",
    "        )\n",
    "        res = res * 100\n",
    "        self.res_format(res)\n",
    "\n",
    "    def impute(self):\n",
    "    \n",
    "        self.imputed_df = self.missing_df.copy()\n",
    "        \n",
    "        missing_df_nan_count = self.missing_df.isnull().sum()\n",
    "\n",
    "        sort_index_li = np.argsort(missing_df_nan_count).tolist()\n",
    "\n",
    "        # for i in tqdm(sort_index_li, desc=f\"Imputing with MNAR ratio: {self.ratio_dict['ratio_mnar']:.3f}, MAR ratio: {self.ratio_dict['ratio_mar']:.3f}, MCAR ratio: {self.ratio_dict['ratio_mcar']:.3f}\"):\n",
    "        for i in sort_index_li:\n",
    "            temp_df = self.imputed_df.copy()\n",
    "\n",
    "            target = temp_df.iloc[:, i] # Get the target column\n",
    "\n",
    "            temp_df = temp_df.iloc[:, temp_df.columns != i] # Kick it out of the data frame\n",
    "\n",
    "            if target.name in self.num_li:\n",
    "                self.num_li.remove(target.name)\n",
    "\n",
    "                # Fill by respective mean\n",
    "                temp_df[self.num_li] = SimpleImputer(missing_values=np.nan, strategy='mean').fit_transform(temp_df[self.num_li])\n",
    "\n",
    "                # Fill by respective mode\n",
    "                temp_df_imputed = SimpleImputer(missing_values=np.nan, strategy='most_frequent').fit_transform(temp_df)\n",
    "\n",
    "                self.num_li.append(target.name)\n",
    "\n",
    "            elif target.name in self.cat_li:\n",
    "                self.cat_li.remove(target.name)\n",
    "                temp_df[self.cat_li] = SimpleImputer(missing_values=np.nan, strategy='most_frequent').fit_transform(temp_df[self.cat_li])\n",
    "                temp_df_imputed = SimpleImputer(missing_values=np.nan, strategy='mean').fit_transform(temp_df)\n",
    "                self.cat_li.append(target.name)\n",
    "\n",
    "            # Select out the training set\n",
    "            y_train = target[target.notnull()]\n",
    "            x_train = temp_df_imputed[y_train.index, :]\n",
    "\n",
    "            # Select out the test set\n",
    "            y_test = target[target.isnull()]\n",
    "            x_test = temp_df_imputed[y_test.index, :]\n",
    "\n",
    "            self.imputer = RandomForestRegressor()\n",
    "            self.imputer.fit(x_train, y_train)\n",
    "            y_predict = self.imputer.predict(x_test)\n",
    "\n",
    "            self.imputed_df.iloc[y_test.index, i] = y_predict\n",
    "\n",
    "    \n",
    "    def cv_eval(self, ratio=0, md=4, fold=10):\n",
    "        # Cross Validation Evaluation\n",
    "        self.clf = xgb.XGBClassifier(max_depth=md)\n",
    "        scores = cross_validate(self.clf, self.imputed_df,\n",
    "                                 self.y_train, cv=fold,\n",
    "                                 scoring=self.metrics)\n",
    "        \n",
    "        score_frame = pd.DataFrame(scores).iloc[:,2:]\n",
    "        self.avg_performance = score_frame.mean()\n",
    "\n",
    "        if self.performance is None and ratio==0:\n",
    "            self.performance = pd.DataFrame(np.nan, index=self.mul_idx, columns=[f'avg_cv_{m}' for m in self.metrics])\n",
    "            base_performance = pd.DataFrame({f'avg_cv_{m}': (self.avg_performance[f'test_{m}'] * 100) for m in self.metrics}, index=[(\"DEFAULT\", f\"even {1/30:.3f}\")])\n",
    "            self.performance = pd.concat([self.performance, base_performance])\n",
    "        elif self.performance is not None and self.mechan is not None and ratio != 0:\n",
    "            for m in self.metrics:\n",
    "                self.performance.loc[pd.Index([(self.mechan, f\"{ratio:.3f}\")]), f'avg_cv_{m}'] = (self.avg_performance[f'test_{m}'] * 100)\n",
    "\n",
    "    def test_eval(self, ratio=0):\n",
    "        \n",
    "        self.clf.fit(self.imputed_df, self.y_train)\n",
    "        y_pred = self.clf.predict(self.X_test)\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        accuracy  = accuracy_score(self.y_test, y_pred)\n",
    "        precision = precision_score(self.y_test, y_pred)\n",
    "        recall    = recall_score(self.y_test, y_pred)\n",
    "        f1        = f1_score(self.y_test, y_pred)\n",
    "\n",
    "        values = np.array([accuracy, precision, recall, f1])#.reshape(1,4)\n",
    "\n",
    "        if self.test_performance is None:\n",
    "            self.test_performance = pd.DataFrame(np.nan, index=self.mul_idx, columns=[f'test_{m}' for m in self.metrics])\n",
    "            base_performance = pd.DataFrame({f'test_{m}':(v * 100) for m, v in zip(self.metrics, values)}, index=[(\"DEFAULT\", f\"even {1/30:.3f}\")])\n",
    "            self.test_performance = pd.concat([self.test_performance, base_performance])\n",
    "        else:\n",
    "            self.test_performance.loc[pd.Index([(self.mechan, f\"{ratio:.3f}\")])] = (values * 100)\n",
    "    \n",
    "    def forward(self, mechan):\n",
    "\n",
    "        self.mechan = mechan\n",
    "        for r in self.ratio_list:\n",
    "\n",
    "            if self.mechan == \"MNAR\":\n",
    "                self.ratio_dict[\"ratio_mnar\"] = r\n",
    "            elif self.mechan == \"MAR\":\n",
    "                self.ratio_dict[\"ratio_mar\"] = r\n",
    "            elif self.mechan == \"MCAR\":\n",
    "                self.ratio_dict[\"ratio_mcar\"] = r\n",
    "\n",
    "            self.insert_null() # Create missing values first\n",
    "            self.impute() # Impute the generated missing data frame\n",
    "            self.cv_eval(r)\n",
    "        \n",
    "            # print(f\"Testing...\\n(mechan: {self.mechan}, ratio_mnar: {self.ratio_dict[\"ratio_mnar\"]:.3f}, ratio_mar: {self.ratio_dict[\"ratio_mar\"]:.3f}, ratio_mcar: {self.ratio_dict[\"ratio_mcar\"]:.3f})\")\n",
    "            self.test_eval(r) # Evaluate the model performance on test set\n",
    "            self.reset_ratio()\n",
    "        \n",
    "    def reset_ratio(self):\n",
    "        self.ratio_dict[\"ratio_mnar\"] = 1/30\n",
    "        self.ratio_dict[\"ratio_mar\"] = 1/30\n",
    "        self.ratio_dict[\"ratio_mcar\"] = 1/30\n",
    "\n",
    "    def forward_(self, mar_dep_col=\"ca\", mar_tar_col=\"thal\", mnar_tar_col=\"cp\"):\n",
    "\n",
    "        self.mar_dep_col, self.mar_tar_col, self.mnar_tar_col = mar_dep_col, mar_tar_col, mnar_tar_col\n",
    "        print(f\"Given mar_dep_col: {self.mar_dep_col}, mar_tar_col: {self.mar_tar_col}, mnar_tar_col: {self.mnar_tar_col}\")\n",
    "\n",
    "        # Evaluate the model performance on training set using CV\n",
    "        \n",
    "        # Start from MNAR\n",
    "        self.forward(mechan=\"MNAR\")\n",
    "\n",
    "        # Then MCAR\n",
    "        self.forward(mechan=\"MCAR\")\n",
    "\n",
    "        # Finally MAR\n",
    "        self.forward(mechan=\"MAR\")\n",
    "\n",
    "    def res_format(self, df, caption=\"\", label=\"\"):\n",
    "\n",
    "            s = df.style.format('{:.2f}\\%')\n",
    "            \n",
    "            # Highlight the result\n",
    "            s = s\\\n",
    "                .highlight_max(props='bfseries:;')\\\n",
    "                .format_index(escape=\"latex\", axis=1)\n",
    "\n",
    "            res = s.to_latex( \n",
    "                multirow_align=\"c\",\n",
    "                position_float=\"centering\",\n",
    "                clines=\"skip-last;data\",\n",
    "                hrules=True,\n",
    "                ).replace(\n",
    "                '\\\\end{tabular}',\n",
    "                '\\\\end{tabular}\\n' + '\\\\caption{' + f'{caption}' + '}\\n\\\\label{' + f'{label}' + '}')\n",
    "            \n",
    "            print(\"\".join(res.split(\"'\")))\n",
    "\n",
    "    def auto_forward(self, var1=\"ca\", var2=\"thal\", var3=\"cp\"):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            - target variables to be inserted missing values\n",
    "\n",
    "        This auto_forward function would automatically permutate these three variables\n",
    "        And set each of them as MAR dependent and target column, MNAR target column, respectively.\n",
    "        \"\"\"\n",
    "        vars = [var1, var2, var3]\n",
    "        iters = itertools.permutations(vars, 3)\n",
    "\n",
    "        for subset in tqdm(iters):\n",
    "            try:\n",
    "                self.forward_(subset[0], subset[1], subset[2])\n",
    "\n",
    "                print(\"Setting shown as follows:\\n Data MAR: \\\\texttt{\" + f\"{self.mar_dep_col}\"  + \"} determines \\\\texttt{\" + f\"{self.mar_tar_col}\"  + \"} \\& Variable MNAR: \\\\texttt{\" + f\"{self.mnar_tar_col}\" \\\n",
    "                + \"}.\\nTraining performance: See table \\\\ref{\" + f'trainpef_{self.mar_dep_col}_{self.mar_tar_col}_{self.mnar_tar_col}'\\\n",
    "                + \"}.\\nTest performance: See table \\\\ref{\" + f'testpef_{self.mar_dep_col}_{self.mar_tar_col}_{self.mnar_tar_col}' + \"}.\\n\")\n",
    "\n",
    "                self.res_format(self.performance, \"Training Performance of setting: MAR (\\\\texttt{\" + f\"{self.mar_dep_col}\"\\\n",
    "                                + \"} determines \\\\texttt{\" + f\"{self.mar_tar_col}\"  + \"}), \\\\texttt{\" + f\"{self.mnar_tar_col}\"\\\n",
    "                                + \"} MNAR\", f'trainpef_{self.mar_dep_col}_{self.mar_tar_col}_{self.mnar_tar_col}')\n",
    "                \n",
    "                self.res_format(self.test_performance, \"Test Performance of setting: MAR (\\\\texttt{\" + f\"{self.mar_dep_col}\"\\\n",
    "                                + \"} determines \\\\texttt{\" + f\"{self.mar_tar_col}\"  + \"}), \\\\texttt{\" + f\"{self.mnar_tar_col}\"\\\n",
    "                                + \"} MNAR\", f'testpef_{self.mar_dep_col}_{self.mar_tar_col}_{self.mnar_tar_col}')\n",
    "            except ValueError:\n",
    "                print(\"Something unusual happen. Please rerun.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhx = test(original_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhx.auto_forward('ca', 'thal', 'age')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
